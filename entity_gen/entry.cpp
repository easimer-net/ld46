// === Copyright (c) 2020 easimer.net. All rights reserved. ===
//
// Purpose: entry point
//

#include "stdafx.h"
#include "common.h"
#include "mmap.h"
#include <algorithm>
#include <cctype>

// TODO(danielm): namespaced type identifiers break the parser

char const* gpszHeader = "// AUTOGENERATED DO NOT MODIFY\n";

enum Field_Flags : unsigned {
    k_unFieldFlags_None         =   0,
    // #memory_only: the field will not be present in a binary file
    k_unFieldFlags_Memory_Only  =   1,
    // #reset: this field will be reset on game load.
    // The function `Reset(decltype(field)& x) -> auto` must be defined for the field's type
    // or the generated code will not compile.
    k_unFieldFlags_Reset        =   2,
};

enum Table_Flags : unsigned {
    k_unTableFlags_None         =   0,
    // #memory_only: the table will not be present in a binary file
    k_unTableFlags_Memory_Only  =   1,
};

struct Field_Type {
    String base;
    unsigned count;
};

struct Field_Definition {
    String name;
    Field_Type type;
    unsigned flags = k_unTableFlags_None;
};

struct Constant {
    String name;
    int value;
};

struct Table_Definition {
    // Type name
    String name;
    // Variable name used in places like Game_Data
    String var_name;
    Vector<Field_Definition> fields;
    unsigned flags = k_unFieldFlags_None;
    Vector<Constant> constants;
};

struct Paths {
    String input;
    String outputHeader, outputSer;
};

enum Token_Kind {
    k_unToken_EOF,
    k_unToken_Unknown,
    k_unToken_Table,
    k_unToken_Curly_Open,
    k_unToken_Curly_Close,
    k_unToken_Square_Open,
    k_unToken_Square_Close,
    k_unToken_Colon,
    k_unToken_Semicolon,
    k_unToken_Pound,
};

struct Token {
    Token_Kind kind;
    String string;
    size_t uiLine, uiCol;
};

#define TAB "    "
#define TAB2 TAB  TAB
#define TAB3 TAB2 TAB
#define TAB4 TAB3 TAB
#define TAB5 TAB4 TAB

static bool IsIdentifierChar(char chCur) {
    return ((chCur >= 'a' && chCur <= 'z') ||
        (chCur >= 'A' && chCur <= 'Z') ||
        (chCur >= '0' && chCur <= '9') ||
        (chCur == '_')
    );
}

#define TOKENIZER_BUFFER_SIZE (256)

static Vector<Token> Tokenize(char const* pszFile, size_t unLength) {
    Vector<Token> ret;
    char pchBuffer[TOKENIZER_BUFFER_SIZE];
    size_t iBuffer = 0;
    bool bInIdentifier = false;
    size_t uiLine = 0;
    size_t uiCol = 0, uiIdCol = 0;

    for (size_t i = 0; i < unLength; i++) {
        char const chCur = pszFile[i];
        if (bInIdentifier) {
            if (IsIdentifierChar(chCur)) {
                pchBuffer[iBuffer++] = chCur;
            } else {
                Token t;
                pchBuffer[iBuffer] = 0;
                t.string = String(pchBuffer);
                if (t.string == "table") {
                    t.kind = k_unToken_Table;
                } else {
                    t.kind = k_unToken_Unknown;
                }
                t.uiLine = uiLine;
                t.uiCol = uiIdCol;

                ret.push_back(std::move(t));
                bInIdentifier = false;

                switch (chCur) {
                case ':': ret.push_back({ k_unToken_Colon, ":", uiLine, uiCol }); break;
                case ';': ret.push_back({ k_unToken_Semicolon, ";", uiLine, uiCol }); break;
                case '#': ret.push_back({ k_unToken_Pound, "#", uiLine, uiCol }); break;
                case '{': ret.push_back({ k_unToken_Curly_Open, "{", uiLine, uiCol }); break;
                case '}': ret.push_back({ k_unToken_Curly_Close, "}", uiLine, uiCol }); break;
                case '[': ret.push_back({ k_unToken_Square_Open, "{", uiLine, uiCol }); break;
                case ']': ret.push_back({ k_unToken_Square_Close, "}", uiLine, uiCol }); break;
                }
            }
        } else {
            switch (chCur) {
            case ' ': break;
            case '\n': uiLine++; uiCol = 0; break;
            case '\r': break;
            case ':': ret.push_back({ k_unToken_Colon, ":", uiLine, uiCol }); break;
            case ';': ret.push_back({ k_unToken_Semicolon, ";", uiLine, uiCol }); break;
            case '#': ret.push_back({ k_unToken_Pound, "#", uiLine, uiCol }); break;
            case '{': ret.push_back({ k_unToken_Curly_Open, "{", uiLine, uiCol }); break;
            case '}': ret.push_back({ k_unToken_Curly_Close, "}", uiLine, uiCol }); break;
            case '[': ret.push_back({ k_unToken_Square_Open, "{", uiLine, uiCol }); break;
            case ']': ret.push_back({ k_unToken_Square_Close, "}", uiLine, uiCol }); break;
            default:
                uiIdCol = uiCol;
                bInIdentifier = true;
                pchBuffer[0] = chCur;
                iBuffer = 1;
                break;
            }
        }

        uiCol++;
    }

    return ret;
}

struct Token_Stream_Iterator {
    Vector<Token> const& v;
    size_t iIdx;
    Token eof;
    Token_Stream_Iterator(Vector<Token> const& v)
        : v(v),
        iIdx(0),
        eof{ k_unToken_EOF, "<eof>" } {}

    void operator++(int) {
        iIdx++;
    }

    Token const* operator->() const {
        if (iIdx < v.size()) {
            return &v[iIdx];
        } else {
            return &eof;
        }
    }
};

#define PRINT_TOKEN_POS() \
    fprintf(stderr, "On line %zu, column %zu:\n", it->uiLine + 1, it->uiCol + 1);
#define EXPECT_TOKEN_TYPE(type, msg) \
    if (it->kind != type) { \
        PRINT_TOKEN_POS(); \
        fprintf(stderr, \
            msg, \
            it->string.c_str()); \
        return false; \
    }

static bool OnlyHasDigits(String const& s) {
    for (char ch : s) {
        if (!('0' <= ch && ch <= '9')) {
            return false;
        }
    }

    return true;
}

static bool SyntaxCheckField(Token_Stream_Iterator& it) {
    while (it->kind == k_unToken_Pound) {
        it++;
        EXPECT_TOKEN_TYPE(k_unToken_Unknown, "Expected identifier after a pound sign, got '%s'\n");
        it++;
    }

    EXPECT_TOKEN_TYPE(k_unToken_Unknown, "Expected identifier at the beginning of a field declaration, got '%s'\n");
    it++;

    EXPECT_TOKEN_TYPE(k_unToken_Colon, "Expected colon in the middle of a field declaration, got '%s'\n");
    it++;

    // base type
    EXPECT_TOKEN_TYPE(k_unToken_Unknown, "Expected identifier at the end of a field declaration, got '%s'\n");
    it++;

    if (it->kind == k_unToken_Square_Open) {
        it++;
        EXPECT_TOKEN_TYPE(k_unToken_Unknown, "Expected number in type specification, got '%s'\n");
        if (!OnlyHasDigits(it->string)) {
            PRINT_TOKEN_POS();
            fprintf(stderr, "Expected number in type specification, got '%s'\n", it->string.c_str());
            return false;
        }
        it++;
        EXPECT_TOKEN_TYPE(k_unToken_Square_Close, "Expected closing square bracket in type specification, got '%s'\n");
        it++;
    }

    EXPECT_TOKEN_TYPE(k_unToken_Semicolon, "Unexpected token at the end of a field declaration: expected semicolon, got '%s'\n");
    it++;

    return true;
}

static bool SyntaxCheckTable(Token_Stream_Iterator& it) {
    bool bRet = true;

    while (it->kind == k_unToken_Pound) {
        it++;
        EXPECT_TOKEN_TYPE(k_unToken_Unknown, "Expected identifier after a pound sign, got '%s'\n");
        it++;
    }

    EXPECT_TOKEN_TYPE(k_unToken_Table, "Expected keyword 'table' at the beginning of a table declaration, got '%s'");
    it++;

    EXPECT_TOKEN_TYPE(k_unToken_Unknown, "Table identifier is missing\n");
    it++;

    // Table optional var_name
    if (it->kind == k_unToken_Unknown) {
        it++;
    }

    EXPECT_TOKEN_TYPE(k_unToken_Curly_Open, "Expected a opening curly brace at the beginning of a table declaration, got '%s'");
    it++;

    while (bRet && it->kind != k_unToken_Curly_Close) {
        bRet &= SyntaxCheckField(it);
    }

    if (bRet) {
        EXPECT_TOKEN_TYPE(k_unToken_Curly_Close, "Expected a closing curly brace after a table declaration, got '%s'\n");
        it++;
    }

    return bRet;
}

static bool SyntaxCheckTop(Vector<Token> const& tokens) {
    bool bRet = true;
    auto it = Token_Stream_Iterator(tokens);

    while (bRet && it->kind != k_unToken_EOF) {
        bRet &= SyntaxCheckTable(it);
    }

    return bRet;
}

#define ASSERT_TOKEN_KIND(_kind) assert(it->kind == _kind)

static String FieldToCField(Field_Definition const& field) {
    String ret = field.type.base;
    ret = ret + ' ' + field.name;
    if (field.type.count != 1) {
        ret = ret + '[' + std::to_string(field.type.count) + ']';
    }

    return ret;
}

static Field_Type ParseType(Token_Stream_Iterator& it) {
    Field_Type ret;
    String typeName;

    ASSERT_TOKEN_KIND(k_unToken_Unknown);
    ret.base = it->string;
    ret.count = 1;
    it++;

    // TODO(danielm): move this to a function like TranslateType
    // once we have multiple typedefs like this
    if (ret.base == "vec4") {
        ret.base = "lm::Vector4";
    }

    if (it->kind == k_unToken_Square_Open) {
        it++;
        ASSERT_TOKEN_KIND(k_unToken_Unknown);
        // NOTE(danielm): can't be negative, syntax check makes sure of that
        ret.count = (unsigned)std::stoi(it->string);
        it++;
        ASSERT_TOKEN_KIND(k_unToken_Square_Close);
        it++;
    }

    return ret;
}

static Field_Definition ParseField(Token_Stream_Iterator& it) {
    Field_Definition def;

    while (it->kind == k_unToken_Pound) {
        it++;
        if (it->string == "reset") {
            def.flags |= k_unFieldFlags_Reset;
        }  else if (it->string == "memory_only") {
            def.flags |= k_unFieldFlags_Memory_Only;
        } else {
            fprintf(stderr, "Unknown field attribute '%s'\n", it->string.c_str());
        }
        it++;
    }

    ASSERT_TOKEN_KIND(k_unToken_Unknown);
    def.name = it->string;
    it++;

    ASSERT_TOKEN_KIND(k_unToken_Colon);
    it++;

    def.type = ParseType(it);

    ASSERT_TOKEN_KIND(k_unToken_Semicolon);
    it++;

    return def;
}

static void ToUpper(String& s) {
    for (auto& ch : s) {
        ch = std::toupper(ch);
    }
}

static void ToLower(String& s) {
    for (auto& ch : s) {
        ch = std::tolower(ch);
    }
}

static String GenerateConstantIdentifier(Table_Definition const& table, Field_Definition const& field) {
    String ret = table.name + '_' + field.name + "_SIZ";
    ToUpper(ret);
    return ret;
}

static Table_Definition ParseTable(Token_Stream_Iterator& it) {
    Table_Definition def;

    while (it->kind == k_unToken_Pound) {
        it++;
        if (it->string == "memory_only") {
            def.flags |= k_unTableFlags_Memory_Only;
        } else {
            fprintf(stderr, "Unknown table attribute '%s'\n", it->string.c_str());
        }
        it++;
    }

    // eat 'table'
    ASSERT_TOKEN_KIND(k_unToken_Table);
    it++;

    // table name
    ASSERT_TOKEN_KIND(k_unToken_Unknown);
    def.name = it->string;
    it++;

    // Optional var_name
    if (it->kind == k_unToken_Unknown) {
        def.var_name = it->string;
        it++;
    }

    ASSERT_TOKEN_KIND(k_unToken_Curly_Open);
    it++;

    while (it->kind != k_unToken_Curly_Close) {
        auto field = ParseField(it);

        if (field.type.count != 1) {
            Constant constant;
            constant.name = GenerateConstantIdentifier(def, field);
            constant.value = field.type.count;
            def.constants.push_back(std::move(constant));
        }

        def.fields.push_back(std::move(field));
    }

    ASSERT_TOKEN_KIND(k_unToken_Curly_Close);
    it++;

    if (def.var_name.size() == 0) {
        def.var_name = def.name + 's';
        ToLower(def.var_name);
    } else {
        if (def.name == "Entity") {
            fprintf(stderr, "Warning: custom var_name on Entity table is ignored\n");
        }
    }

    return def;
}

static Vector<Table_Definition> ParseTop(Vector<Token> const& tokens) {
    Vector<Table_Definition> ret;
    auto it = Token_Stream_Iterator(tokens);

    while (it->kind != k_unToken_EOF) {
        ret.push_back(ParseTable(it));
    }

    return ret;
}

static void WriteHeaderInclude(FILE* hFile, char const* pszFile) {
    fprintf(hFile, "#include %s\n", pszFile);
}

static void WriteHeaderInclude(FILE* hFile, String const& pszFile) {
    fprintf(hFile, "#include %s\n", pszFile.c_str());
}

#define EMIT_INCLUDE(file) WriteHeaderInclude(hFile, file)

static void GenerateHeaderFile(String const& pszPath, Vector<Table_Definition> const& tables) {
    char const* apszIncludes[] = { "<cstdint>", "<vector>", "<unordered_map>", "<optional>",
        "<variant>", "<utils/linear_math.h>", "\"textures.h\"", "\"animator.h\"", "\"entity_gen.h\"" };
    constexpr auto unIncludesCount = sizeof(apszIncludes) / sizeof(apszIncludes[0]);
    FILE* hFile = fopen(pszPath.c_str(), "wb");
    if (hFile != NULL) {
        fprintf(hFile, gpszHeader);
        fprintf(hFile, "#pragma once\n");
        for (size_t i = 0; i < unIncludesCount; i++) EMIT_INCLUDE(apszIncludes[i]);
        fprintf(hFile, "\n");

        for (auto& table : tables) {
            // Emit constants first
            for (auto const& constant : table.constants) {
                fprintf(hFile, "#define %s %d\n", constant.name.c_str(), constant.value);
            }

            fprintf(hFile, "struct %s {\n", table.name.c_str());
            bool bHasTempField = false;
            for (auto& field : table.fields) {
                fprintf(hFile, "    %s;\n", FieldToCField(field).c_str());
                bHasTempField |= (field.flags & k_unFieldFlags_Reset) != 0;
            }

            if (bHasTempField) {
                fprintf(hFile, "    void ResetTransients() {\n");
                for (auto& field : table.fields) {
                    if ((field.flags & k_unFieldFlags_Reset) != 0) {
                        fprintf(hFile, "        Reset(%s);\n", field.name.c_str());
                    }
                }
                fprintf(hFile, "    }\n");
            }

            fprintf(hFile, "};\n\n");
        }

        fprintf(hFile, "struct Game_Data { \n    TABLE_COLLECTION();\n    Vector<Entity> entities;\n");

        for (auto& table : tables) {
            if (table.name != "Entity") {
                fprintf(hFile, "    ADD_TABLE(%s, %s);\n", table.var_name.c_str(), table.name.c_str());
            }
        }

        fprintf(hFile, "    void Clear() { \n");
        for (auto& table : tables) {
            if (table.name != "Entity") {
                fprintf(hFile, "        %s.clear();\n", table.var_name.c_str());
            } else {
                fprintf(hFile, "        entities.clear();\n");
            }
        }
        fprintf(hFile, "    }\n};\n");
        fclose(hFile);
    }
}

static char const* gpszSaveLevelHeader = "\n\
void SaveLevel(char const* pszPath, Game_Data const& game_data) { \n\
    auto hFile = fopen(pszPath, \"wb\");                          \n\
    if(hFile != NULL) {                                           \n\
        defer([=]() { fclose(hFile); });                          \n\
        Level_Header hdr;                                         \n\
        fwrite(&hdr, sizeof(hdr), 1, hFile);                      \n\
";

static char const* gpszSaveLevelFooter = "\n\
    } else {                                            \n\
        printf(\"SaveLevel(%%s) failed!\\n\", pszPath);  \n\
    }                                                   \n\
}\n";

static char const* gpszLoadLevelHeader = "\n\
void LoadLevel(char const* pszPath, Game_Data& aGameData) { \n\
    auto hFile = fopen(pszPath, \"rb\");                    \n\
    if(hFile != NULL) {                                     \n\
        defer([=]() { fclose(hFile); });                    \n\
        Level_Header hdr;                                   \n\
        fread(&hdr, sizeof(hdr), 1, hFile);                 \n\
        if(!CheckHeader(hdr)) { return; }                   \n\
";

static char const* gpszLoadLevelFooter = "\n\
    } else {                                            \n\
        printf(\"LoadLevel(%%s) failed!\\n\", pszPath);  \n\
    }                                                   \n\
}\n";

static char const* gpszEntityWriteHeader = "\
        uint16_t const unEntityCount = CountEntities(game_data);    \n\
        fwrite(&unEntityCount, sizeof(unEntityCount), 1, hFile);    \n\
        for (Entity_ID i = 0; i < game_data.entities.size(); i++) { \n\
            auto const& ent = game_data.entities[i];                \n\
            Write(hFile, i);                                        \n\
";

static char const* gpszEntityWriteFooter = "\
        }\n";

static char const* gpszEntityReadHeader = "\
        uint16_t unEntityCount;                                     \n\
        fread(&unEntityCount, sizeof(unEntityCount), 1, hFile);     \n\
        for (unsigned i = 0; i < unEntityCount; i++) {              \n\
            Entity_ID iEnt;                                         \n\
            Read(hFile, &iEnt);                                     \n\
            auto& ent = AllocateEntity(aGameData, iEnt);            \n\
";

static char const* gpszEntityReadFooter = "\
        }\n";

static String GetChunkIdConstant(Table_Definition const& table) {
    String tableCapital = "CHUNKID_" + table.name;
    ToUpper(tableCapital);
    return tableCapital;
}

static void DefineSerializationConstants(FILE* hFile, Vector<Table_Definition> const& tables) {
    uint16_t chunkId = 1;
    for (auto& table : tables) {
        if ((table.flags & k_unTableFlags_Memory_Only) == 0) {
            auto const tableCapital = GetChunkIdConstant(table);
            fprintf(hFile, "#define %s (%d)\n", tableCapital.c_str(), chunkId++);
        }
    }
}

static void EmitSaveLevel(FILE* hFile, Vector<Table_Definition> const& tables) {
    fprintf(hFile, gpszSaveLevelHeader);

    // Entity table is special
    for (auto& table : tables) {
        if (table.name == "Entity") {
            fprintf(hFile, gpszEntityWriteHeader);
            for (auto& field : table.fields) {
                if ((field.flags & k_unFieldFlags_Memory_Only) == 0) {
                    fprintf(hFile, TAB3 "Write(hFile, ent.%s);\n", field.name.c_str());
                }
            }
            fprintf(hFile, gpszEntityWriteFooter);
            break;
        }
    }

    for (auto& table : tables) {
        if ((table.flags & k_unTableFlags_Memory_Only) == 0 && table.name != "Entity") {
            auto const tableCapital = GetChunkIdConstant(table);
            fprintf(hFile, TAB2 "// Dump %s\n", table.var_name.c_str());
            fprintf(hFile, TAB2 "BEGIN_SECTION_WRITE(%s, game_data.%s)\n",
                tableCapital.c_str(), table.var_name.c_str());
            fprintf(hFile, TAB2 "for(auto& kv : game_data.%s) {\n",
                table.var_name.c_str());
            fprintf(hFile, TAB3 "Write(hFile, kv.first);\n");
            for (auto& field : table.fields) {
                if ((field.flags & k_unFieldFlags_Memory_Only) == 0) {
                    if (field.type.count == 1) {
                        fprintf(hFile, TAB3 "Write(hFile, kv.second.%s);\n", field.name.c_str());
                    } else {
                        auto const pszSizeConst = GenerateConstantIdentifier(table, field);
                        fprintf(hFile, TAB3 "Write(hFile, %s, kv.second.%s);\n", pszSizeConst.c_str(), field.name.c_str());
                    }
                }
            }
            fprintf(hFile, TAB2 "}\n");
            fprintf(hFile, TAB2 "END_SECTION_WRITE()\n\n");
        }
    }

    fprintf(hFile, gpszSaveLevelFooter);
}

static void EmitLoadLevel(FILE* hFile, Vector<Table_Definition> const& tables) {
    fprintf(hFile, gpszLoadLevelHeader);

    // Entity table is special
    for (auto& table : tables) {
        if (table.name == "Entity") {
            fprintf(hFile, gpszEntityReadHeader);
            for (auto& field : table.fields) {
                if ((field.flags & k_unFieldFlags_Memory_Only) == 0) {
                    fprintf(hFile, TAB3 "Read(hFile, &ent.%s);\n", field.name.c_str());
                }
            }
            fprintf(hFile, gpszEntityReadFooter);
            break;
        }
    }

    fprintf(hFile, TAB2 "while (!feof(hFile)) {\n");
    fprintf(hFile, TAB3 "uint16_t uiChunkId, unCount;\n");
    fprintf(hFile, TAB3 "Entity_ID iEnt;\n");
    fprintf(hFile, TAB3 "fread(&uiChunkId, sizeof(uiChunkId), 1, hFile);\n");
    fprintf(hFile, TAB3 "fread(&unCount, sizeof(unCount), 1, hFile);\n");
    fprintf(hFile, TAB3 "for (unsigned i = 0; i < unCount; i++) {\n");
    fprintf(hFile, TAB4 "Read(hFile, &iEnt);\n");
    fprintf(hFile, TAB4 "switch(uiChunkId) {\n");
    for (auto& table : tables) {
        if (table.name != "Entity" && (table.flags & k_unTableFlags_Memory_Only) == 0) {
            auto const pszChunkId = GetChunkIdConstant(table);
            fprintf(hFile, TAB4 "case %s:\n", pszChunkId.c_str());
            fprintf(hFile, TAB4 "{\n");
            fprintf(hFile, TAB5 "%s buf;\n", table.name.c_str());
            for (auto& field : table.fields) {
                if ((field.flags & k_unFieldFlags_Memory_Only) == 0) {
                    if (field.type.count == 1) {
                        fprintf(hFile, TAB5 "Read(hFile, &buf.%s);\n", field.name.c_str());
                    } else {
                        auto const pszSizeConst = GenerateConstantIdentifier(table, field);
                        fprintf(hFile, TAB5 "Read(hFile, %s, buf.%s);\n", pszSizeConst.c_str(), field.name.c_str());
                    }
                }
            }
            fprintf(hFile, TAB5 "aGameData.%s[iEnt] = buf;\n", table.var_name.c_str());
            fprintf(hFile, TAB5 "break;\n");
            fprintf(hFile, TAB4 "}\n");
        }
    }
    fprintf(hFile, TAB4 "}\n");
    fprintf(hFile, TAB3 "}\n");
    fprintf(hFile, TAB2 "}\n");

    fprintf(hFile, gpszLoadLevelFooter);
}

static void GenerateSerializationCode(String const& pszPath, String const& pszGameName, Vector<Table_Definition> const& tables) {
    FILE* hFile = fopen(pszPath.c_str(), "wb");
    if (hFile != NULL) {
        fprintf(hFile, gpszHeader);
        fprintf(hFile, "#define SERIALIZATION_CPP\n");
        EMIT_INCLUDE('\"' + pszGameName + ".h\"");
        EMIT_INCLUDE("\"serialization_common.h\"");

        DefineSerializationConstants(hFile, tables);
        EmitSaveLevel(hFile, tables);
        EmitLoadLevel(hFile, tables);
        fclose(hFile);
    }
}

static bool Process(Paths const& paths, String const& pszGameName) {
    bool bRet = false;
    char const* pszFile;
    size_t unLen;

    auto hMap = MapFile(&pszFile, &unLen, paths.input.c_str());
    if (hMap != NULL) {
        auto const tokens = Tokenize(pszFile, unLen);
        UnmapFile(hMap);
        bRet = SyntaxCheckTop(tokens);

        if (bRet) {
            auto const tables = ParseTop(tokens);
            GenerateHeaderFile(paths.outputHeader, tables);
            GenerateSerializationCode(paths.outputSer, pszGameName, tables);
        }
    } else {
        fprintf(stderr, "Couldn't find entity definition file '%s'\n", paths.input.c_str());
    }
    return bRet;
}

// entity_gen.exe game_dir
// we need to create a <gamename>.h with all the entity typedefs and
// a serialization.cpp
// entity_gen.exe path/outdir path/entities.def gamename
int main(int argc, char** argv) {
    printf("Entity Generator\n");
    if (argc >= 4) {
        auto const pathOut = String(argv[1]);
        auto const pszGameName = String(argv[3]);
        Paths const paths = {
            String(argv[2]), // path to entities.def
            pathOut + "/" + pszGameName + ".h",
            pathOut + "/serialization.cpp",
        };
        printf("Paths:\nDefinition file:\t'%s'\nHeader output:\t'%s'\nSerializer output:\t'%s'\n",
            paths.input.c_str(), paths.outputHeader.c_str(), paths.outputSer.c_str());
        Process(paths, pszGameName);
    } else {
        fprintf(stderr, "Usage: %s path/outdir path/entities.def game_name\n", argv[0]);
        fprintf(stderr, "path/outdir: <game_name>.h and serialization.cpp will be placed there\n");
        fprintf(stderr, "path/entities.def: path to the entities definition file\n");
        fprintf(stderr, "game_name: name of the game\n");
    }
    return 0;
}
